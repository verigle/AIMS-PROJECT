{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lora import LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koomi_aims_ac_za/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from aurora import AuroraSmall, Batch, Metadata, rollout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cdsapi\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import gcsfs\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from aurora import Batch, Metadata\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "from utils import get_surface_feature_target_data, get_atmos_feature_target_data\n",
    "from utils import get_static_feature_target_data, create_batch, predict_fn, rmse_weights\n",
    "from utils import rmse_fn, plot_rmses, custom_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch import ERA5ZarrDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "\n",
    "store = fs.get_mapper('gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr')\n",
    "full_era5 = xr.open_zarr(store=store, consolidated=True, chunks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time, end_time = '2022-12-01', '2023-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lat_max = -22.00 \n",
    "lat_min = -37.75  \n",
    "\n",
    "lon_min = 15.25   \n",
    "lon_max = 35.00   \n",
    "sliced_era5 = (\n",
    "    full_era5\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ERA5ZarrDataset(sliced_era5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=8, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_labels = next(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aurora import AuroraSmall\n",
    "\n",
    "# model = AuroraSmall(\n",
    "#     use_lora=False,  # Model was not fine-tuned.\n",
    "#     autocast=True,  # Use AMP.\n",
    "# )\n",
    "# # model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-small-pretrained.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"../model/aurora-pretrained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AuroraSmall(\n",
    "    use_lora=False,  # Model was not fine-tuned.\n",
    "    autocast=True,  # Use AMP.\n",
    ")\n",
    "model.load_state_dict(torch.load('../model/aurora-pretrained.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    parameters, trainable = 0, 0\n",
    "    \n",
    "    for _, p in model.named_parameters():\n",
    "        parameters += p.numel()\n",
    "        trainable += p.numel() if p.requires_grad else 0\n",
    "    print(trainable)\n",
    "    print(f\"trainable parameters: {trainable:,}/{parameters:,} ({100 * trainable / parameters:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112797584\n",
      "trainable parameters: 112,797,584/112,797,584 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "trainable parameters: 0/112,797,584 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.backbone.time_mlp.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131584\n",
      "trainable parameters: 131,584/112,797,584 (0.12%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.backbone.encoder_layers[0].blocks[0].norm1.ln_modulation.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263168\n",
      "trainable parameters: 263,168/112,797,584 (0.23%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get south africa Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "\n",
    "store = fs.get_mapper('gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr')\n",
    "full_era5 = xr.open_zarr(store=store, consolidated=True, chunks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time, end_time = '2022-12-01', '2023-01-31'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "atmostpheric_variables = [\"temperature\", \"u_component_of_wind\", \"v_component_of_wind\", \"specific_humidity\", \"geopotential\"]\n",
    "surface_vars = ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure']\n",
    "static_variables = [\"land_sea_mask\", \"soil_type\", \"geopotential_at_surface\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lat_max = -22.00 \n",
    "lat_min = -37.75  \n",
    "\n",
    "lon_min = 15.25   \n",
    "lon_max = 35.00   \n",
    "sliced_era5_SA = (\n",
    "    full_era5\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )\n",
    "    .isel(time=slice(None, -2))\n",
    ")\n",
    "\n",
    "target_sliced_era5_SA = (\n",
    "    full_era5\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )  \n",
    "    .isel(time=slice(2, None))  # Skip the first two time steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surf_vars_ds_SA = sliced_era5_SA[surface_vars]\n",
    "\n",
    "# target_surf_vars_ds_SA = target_sliced_era5_SA[surface_vars]\n",
    "\n",
    "# atmos_vars_ds_SA = sliced_era5_SA[atmostpheric_variables]\n",
    "\n",
    "# target_atmos_vars_ds_SA = target_sliced_era5_SA[atmostpheric_variables]\n",
    "\n",
    "# static_vars_ds_SA = sliced_era5_SA[static_variables]\n",
    "\n",
    "# target_static_vars_ds_SA = target_sliced_era5_SA[static_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ERA5ZarrDataset(Dataset):\n",
    "#     def __init__(self, surf_vars_ds, atmos_vars_ds, static_vars_ds, sequence_length):\n",
    "#         self.surf_vars_ds = surf_vars_ds\n",
    "#         self.atmos_vars_ds = atmos_vars_ds\n",
    "#         self.static_vars_ds = static_vars_ds\n",
    "#         self.sequence_length = sequence_length\n",
    "#         self.time_indices = range(sequence_length, len(surf_vars_ds.time))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.time_indices)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         i = self.time_indices[idx]\n",
    "\n",
    "#         surf_vars = {\n",
    "#             \"2t\": torch.from_numpy(self.surf_vars_ds[\"2m_temperature\"].values[[i - 1, i]][None]),\n",
    "#             \"10u\": torch.from_numpy(self.surf_vars_ds[\"10m_u_component_of_wind\"].values[[i - 1, i]][None]),\n",
    "#             \"10v\": torch.from_numpy(self.surf_vars_ds[\"10m_v_component_of_wind\"].values[[i - 1, i]][None]),\n",
    "#             \"msl\": torch.from_numpy(self.surf_vars_ds[\"mean_sea_level_pressure\"].values[[i - 1, i]][None]),\n",
    "#         }\n",
    "\n",
    "#         static_vars = {\n",
    "#             \"z\": torch.from_numpy(self.static_vars_ds[\"geopotential_at_surface\"].values),\n",
    "#             \"slt\": torch.from_numpy(self.static_vars_ds[\"soil_type\"].values),\n",
    "#             \"lsm\": torch.from_numpy(self.static_vars_ds[\"land_sea_mask\"].values),\n",
    "#         }\n",
    "\n",
    "#         atmos_vars = {\n",
    "#             \"t\": torch.from_numpy(self.atmos_vars_ds[\"temperature\"].values[[i - 1, i]][None]),\n",
    "#             \"u\": torch.from_numpy(self.atmos_vars_ds[\"u_component_of_wind\"].values[[i - 1, i]][None]),\n",
    "#             \"v\": torch.from_numpy(self.atmos_vars_ds[\"v_component_of_wind\"].values[[i - 1, i]][None]),\n",
    "#             \"q\": torch.from_numpy(self.atmos_vars_ds[\"specific_humidity\"].values[[i - 1, i]][None]),\n",
    "#             \"z\": torch.from_numpy(self.atmos_vars_ds[\"geopotential\"].values[[i - 1, i]][None]),\n",
    "#         }\n",
    "\n",
    "#         metadata=Metadata(\n",
    "#         lat=torch.from_numpy(self.surf_vars_ds.latitude.values),\n",
    "#         lon=torch.from_numpy(self.surf_vars_ds.longitude.values),\n",
    "#         time=(self.surf_vars_ds.time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "#         atmos_levels=tuple(int(level) for level in self.atmos_vars_ds.level.values)\n",
    "#     )\n",
    "\n",
    "\n",
    "#         return Batch(surf_vars=surf_vars, static_vars=static_vars, atmos_vars=atmos_vars, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SA_batches = ERA5ZarrDataset(surf_vars_ds_SA, atmos_vars_ds_SA, static_vars_ds_SA,1)\n",
    "# target_SA_batches = ERA5ZarrDataset(target_surf_vars_ds_SA, target_atmos_vars_ds_SA, target_static_vars_ds_SA,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRA(nn.Module):\n",
    "    def __init__(self, original_layer, rank=4):\n",
    "        super(LoRA, self).__init__()\n",
    "        self.original_layer = original_layer\n",
    "        self.rank = rank\n",
    "        self.lora_A = nn.Parameter(torch.randn(rank, original_layer.in_features))\n",
    "        self.lora_B = nn.Parameter(torch.randn(original_layer.out_features, rank))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.original_layer(x) + (x @ self.lora_A.T) @ self.lora_B.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora_to_model(model, rank=4):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            setattr(model, name, LoRA(module, rank))\n",
    "        else:\n",
    "            apply_lora_to_model(module, rank)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = apply_lora_to_model(model, rank=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apply_lora_to_model(model, rank=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2153600\n",
      "trainable parameters: 2,153,600/114,951,184 (1.87%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# import torch.nn as nn\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# model.train()\n",
    "# for epoch in range(1):\n",
    "#     print(\"start\")\n",
    "#     for inputs, targets in zip(SA_batches, target_SA_batches):\n",
    "#         print(\"OK\")\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         print(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"aurora_lora_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sa_latitudes, sa_longitudes = sliced_era5_SA.latitude, sliced_era5_SA.longitude\n",
    "\n",
    "# # Compute RMSE weights\n",
    "# sa_rmse_weights = rmse_weights(sa_latitudes, sa_longitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import AuroraLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = AuroraLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def training(model, criterion, num_epochs,\n",
    "#              dataset=None,\n",
    "#              dataset_name=\"ERA5\", \n",
    "#              accumulation_steps=8\n",
    "#              ):\n",
    "#     selected_times = dataset.time\n",
    "#     loss_list=[]\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         for i in range(0, len(selected_times)-3):\n",
    "#             # get current and previous time step data\n",
    "\n",
    "#             sa_feature_data =  (\n",
    "#                     dataset\n",
    "#                     .sel(time=slice(selected_times[i], selected_times[i+1]))\n",
    "#                 )\n",
    "\n",
    "#             sa_target_data =  (\n",
    "#                     dataset\n",
    "#                     .sel(time=slice(selected_times[i+2], selected_times[i+3]))\n",
    "#                 )\n",
    "            \n",
    "#             # get each type of data(surface, static atmosphere)\n",
    "\n",
    "#             sa_feature_surface_data, sa_target_surface_data = get_surface_feature_target_data(sa_feature_data, sa_target_data)\n",
    "#             sa_feature_atmos_data, sa_target_atmos_data = get_atmos_feature_target_data(sa_feature_data, sa_target_data)\n",
    "#             sa_feature_static_data, sa_target_static_data = get_static_feature_target_data(sa_feature_data, sa_target_data)\n",
    "            \n",
    "#             # create batch for each of them\n",
    "\n",
    "#             input =  create_batch(sa_feature_surface_data, sa_feature_atmos_data, sa_feature_static_data)\n",
    "#             target = create_batch(sa_target_surface_data, sa_target_atmos_data, sa_target_static_data)\n",
    "            \n",
    "#             print(\"Start\")\n",
    "                        \n",
    "#             # Forward pass\n",
    "#             outputs = model(input)\n",
    "#             loss = criterion(outputs, target, dataset_name)\n",
    "#             loss = loss / accumulation_steps  # Normalize loss\n",
    "#             print(loss.detach().numpy())\n",
    "            \n",
    "#             # Backward pass\n",
    "#             loss.backward()\n",
    "            \n",
    "#             # Update weights and reset gradients every accumulation_steps\n",
    "#             if (i + 1) % accumulation_steps == 0:\n",
    "#                 optimizer.step()\n",
    "#                 optimizer.zero_grad()\n",
    "        \n",
    "#         # Handle remaining gradients if dataset size is not divisible by accumulation_steps\n",
    "#         if (i + 1) % accumulation_steps != 0:\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "        \n",
    "#         loss_list.append(loss.detach().numpy())\n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "#     return model, loss_list\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # optimizer.zero_grad()\n",
    "#     # outputs = model(sa_feature_bacth)\n",
    "#     # print(\"Prediction done\")\n",
    "#     # loss = criterion(outputs, sa_target_bacth, \"ERA5\")\n",
    "#     # print(loss)\n",
    "#     # loss.backward()\n",
    "#     # optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training(model, criterion, num_epochs=1,\n",
    "#              dataset=sliced_era5_SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "86885710.0\n",
      "Start\n",
      "95813010.0\n",
      "Start\n",
      "86252984.0\n",
      "Start\n",
      "92127160.0\n",
      "Start\n",
      "97635850.0\n",
      "Start\n",
      "102172870.0\n",
      "Start\n",
      "102170990.0\n",
      "Start\n",
      "95612216.0\n",
      "Start\n",
      "99822640.0\n",
      "Start\n",
      "99889336.0\n",
      "Start\n",
      "91303560.0\n",
      "Start\n",
      "100477960.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msliced_era5_SA\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/notebooks/../src/train.py:52\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, criterion, num_epochs, optimizer, dataset, dataset_name, accumulation_steps)\u001b[0m\n\u001b[1;32m     48\u001b[0m sa_feature_static_data, sa_target_static_data \u001b[38;5;241m=\u001b[39m get_static_feature_target_data(sa_feature_data, sa_target_data)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# create batch for each of them\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m  \u001b[43mcreate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_feature_surface_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msa_feature_atmos_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msa_feature_static_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m target \u001b[38;5;241m=\u001b[39m create_batch(sa_target_surface_data, sa_target_atmos_data, sa_target_static_data)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/notebooks/../src/utils.py:75\u001b[0m, in \u001b[0;36mcreate_batch\u001b[0;34m(surf_vars_ds, atmos_vars_ds, static_vars_ds, i)\u001b[0m\n\u001b[1;32m     60\u001b[0m surf_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2t\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2m_temperature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10u\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10m_u_component_of_wind\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10v\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10m_v_component_of_wind\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsl\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_sea_level_pressure\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     65\u001b[0m }\n\u001b[1;32m     67\u001b[0m static_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(static_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeopotential_at_surface\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslt\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(static_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoil_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlsm\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(static_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mland_sea_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m     71\u001b[0m }\n\u001b[1;32m     73\u001b[0m atmos_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43matmos_vars_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mu_component_of_wind\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_component_of_wind\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecific_humidity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfrom_numpy(atmos_vars_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeopotential\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, i]][\u001b[38;5;28;01mNone\u001b[39;00m]),\n\u001b[1;32m     79\u001b[0m }\n\u001b[1;32m     81\u001b[0m metadata\u001b[38;5;241m=\u001b[39mMetadata(\n\u001b[1;32m     82\u001b[0m lat\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds\u001b[38;5;241m.\u001b[39mlatitude\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m     83\u001b[0m lon\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(surf_vars_ds\u001b[38;5;241m.\u001b[39mlongitude\u001b[38;5;241m.\u001b[39mvalues),\n\u001b[1;32m     84\u001b[0m time\u001b[38;5;241m=\u001b[39m(surf_vars_ds\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime64[s]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()[i],),\n\u001b[1;32m     85\u001b[0m atmos_levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mint\u001b[39m(level) \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m atmos_vars_ds\u001b[38;5;241m.\u001b[39mlevel\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Batch(surf_vars\u001b[38;5;241m=\u001b[39msurf_vars, static_vars\u001b[38;5;241m=\u001b[39mstatic_vars, atmos_vars\u001b[38;5;241m=\u001b[39matmos_vars, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/dataarray.py:814\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/variable.py:507\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/variable.py:301\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    303\u001b[0m         kind \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/indexing.py:509\u001b[0m, in \u001b[0;36mExplicitlyIndexed.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: np\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    506\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# Leave casting to an array up to the underlying array type.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Version(np\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 509\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_duck_array(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/indexing.py:835\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/indexing.py:832\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/indexing.py:789\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/indexing.py:652\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m     array \u001b[38;5;241m=\u001b[39m apply_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/backends/zarr.py:223\u001b[0m, in \u001b[0;36mZarrArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, indexing\u001b[38;5;241m.\u001b[39mOuterIndexer):\n\u001b[1;32m    222\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oindex\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVECTORIZED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/core/indexing.py:1013\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1013\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/xarray/backends/zarr.py:213\u001b[0m, in \u001b[0;36mZarrArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/zarr/core.py:795\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    793\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvindex[selection]\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_pure_orthogonal_indexing(pure_selection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim):\n\u001b[0;32m--> 795\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_orthogonal_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_basic_selection(pure_selection, fields\u001b[38;5;241m=\u001b[39mfields)\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/zarr/core.py:1077\u001b[0m, in \u001b[0;36mArray.get_orthogonal_selection\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;66;03m# setup indexer\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m indexer \u001b[38;5;241m=\u001b[39m OrthogonalIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/zarr/core.py:1340\u001b[0m, in \u001b[0;36mArray._get_selection\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m math\u001b[38;5;241m.\u001b[39mprod(out_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# allow storage to get multiple items at once\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n\u001b[0;32m-> 1340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_getitems\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlout_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/zarr/core.py:2181\u001b[0m, in \u001b[0;36mArray._chunk_getitems\u001b[0;34m(self, lchunk_coords, lchunk_selection, out, lout_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   2180\u001b[0m         contexts \u001b[38;5;241m=\u001b[39m ConstantMap(ckeys, constant\u001b[38;5;241m=\u001b[39mContext(meta_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array))\n\u001b[0;32m-> 2181\u001b[0m     cdatas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ckey, chunk_select, out_select \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ckeys, lchunk_selection, lout_selection):\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ckey \u001b[38;5;129;01min\u001b[39;00m cdatas:\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/zarr/storage.py:1426\u001b[0m, in \u001b[0;36mFSStore.getitems\u001b[0;34m(self, keys, contexts)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgetitems\u001b[39m(\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28mself\u001b[39m, keys: Sequence[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m, contexts: Mapping[\u001b[38;5;28mstr\u001b[39m, Context]\n\u001b[1;32m   1424\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m   1425\u001b[0m     keys_transformed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_key(key): key \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys}\n\u001b[0;32m-> 1426\u001b[0m     results_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitems\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys_transformed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1427\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results_transformed\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/fsspec/mapping.py:105\u001b[0m, in \u001b[0;36mFSMap.getitems\u001b[0;34m(self, keys, on_error)\u001b[0m\n\u001b[1;32m    103\u001b[0m oe \u001b[38;5;241m=\u001b[39m on_error \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    107\u001b[0m         out \u001b[38;5;241m=\u001b[39m {keys2[\u001b[38;5;241m0\u001b[39m]: out}\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/fsspec/asyn.py:91\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mrun_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# this loops allows thread to get interrupted\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import training\n",
    "\n",
    "training(model, criterion,\n",
    "             num_epochs=1,  optimizer=optimizer, dataset = sliced_era5_SA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_running_loss = 0.0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for i in range(0, len(target_sliced_era5_SA.time)-3):\n",
    "        # get current and previous time step data\n",
    "\n",
    "            sa_feature_data =  (\n",
    "                    sliced_era5_SA\n",
    "                    .sel(time=slice(selected_times[i], selected_times[i+1]))\n",
    "                )\n",
    "\n",
    "            sa_target_data =  (\n",
    "                    target_sliced_era5_SA\n",
    "                    .sel(time=slice(selected_times[i+2], selected_times[i+3]))\n",
    "                )\n",
    "            \n",
    "            # get each type of data(surface, static atmosphere)\n",
    "\n",
    "            sa_feature_surface_data, sa_target_surface_data = get_surface_feature_target_data(sa_feature_data, sa_target_data)\n",
    "            sa_feature_atmos_data, sa_target_atmos_data = get_atmos_feature_target_data(sa_feature_data, sa_target_data)\n",
    "            sa_feature_static_data, sa_target_static_data = get_static_feature_target_data(sa_feature_data, sa_target_data)\n",
    "            \n",
    "            # create batch for each of them\n",
    "\n",
    "            input =  create_batch(sa_feature_surface_data, sa_feature_atmos_data, sa_feature_static_data)\n",
    "            target = create_batch(sa_target_surface_data, sa_target_atmos_data, sa_target_static_data)\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"Start\")\n",
    "            \n",
    "        \n",
    "\n",
    "            \n",
    "            # inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input)\n",
    "            loss = criterion(outputs, target, \"ERA5\")\n",
    "            loss = loss / accumulation_steps  # Normalize loss\n",
    "            loss_list.append(loss.detach().numpy())\n",
    "            print(loss)\n",
    "\n",
    "\n",
    "print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Prediction done\n",
      "tensor(80327112., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(73870288., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(71279416., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(66979388., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(76102832., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(67231240., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(58614704., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(55923936., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(53904288., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(52293720., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(53105628., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(49706236., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(47634212., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(41055844., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(38299132., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(33816268., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(39691012., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(42012164., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(33388950., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(34213344., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(30999476., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(31589654., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(29364390., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(28333002., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(25883004., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(29208592., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(25703238., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(27869326., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(26632116., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(25687588., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(32170082., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(29419610., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(40245000., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(26212446., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(32116296., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(31494134., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(30765200., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(26905836., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(23809776., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(24449230., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22905530., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21791972., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22354418., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(25172724., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(24263340., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21916140., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22620568., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(27734970., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21010828., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22029784., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22428246., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21524434., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22586060., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21530960., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(26353092., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21127948., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21982366., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21236542., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22196124., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20656078., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20417586., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18970948., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20080552., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20694100., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20440400., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22566104., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(17326216., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(19529356., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18972038., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21992630., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18460864., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(19171774., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(19396044., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18437434., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20611096., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(19352006., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22980710., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(17860186., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(17809980., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18167484., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18144598., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18782698., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(17782434., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21183594., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22130520., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(17689530., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18731296., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(19827146., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(16978054., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22844256., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(19689590., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20758764., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(17735108., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(18248282., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21786624., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20930404., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21524638., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20834290., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(19458034., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21708878., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20302614., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(20814962., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(21554094., grad_fn=<SqrtBackward0>)\n",
      "Start\n",
      "Prediction done\n",
      "tensor(22205518., grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m custom_rmse(target_tensor, output_tensor, sa_rmse_weights)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "sa_latitudes = target_sliced_era5_SA.latitude\n",
    "sa_longitudes = target_sliced_era5_SA.longitude\n",
    "\n",
    "selected_times =  target_sliced_era5_SA.time\n",
    "sa_rmses_list=[]\n",
    "for i in range(0, len(target_sliced_era5_SA.time)-3):\n",
    "    # get current and previous time step data\n",
    "    world_feature_data =  (\n",
    "            target_sliced_era5_SA\n",
    "            .sel(time=slice(selected_times[i], selected_times[i+1]))\n",
    "        )\n",
    "    sa_feature_data =  (\n",
    "            sliced_era5_SA\n",
    "            .sel(time=slice(selected_times[i], selected_times[i+1]))\n",
    "        )\n",
    "\n",
    "    sa_target_data =  (\n",
    "            target_sliced_era5_SA\n",
    "            .sel(time=slice(selected_times[i+2], selected_times[i+3]))\n",
    "        )\n",
    "    \n",
    "    # get each type of data(surface, static atmosphere)\n",
    "\n",
    "    sa_feature_surface_data, sa_target_surface_data = get_surface_feature_target_data(sa_feature_data, sa_target_data)\n",
    "    sa_feature_atmos_data, sa_target_atmos_data = get_atmos_feature_target_data(sa_feature_data, sa_target_data)\n",
    "    sa_feature_static_data, sa_target_static_data = get_static_feature_target_data(sa_feature_data, sa_target_data)\n",
    "    \n",
    "    # create batch for each of them\n",
    "\n",
    "    sa_feature_bacth =  create_batch(sa_feature_surface_data, sa_feature_atmos_data, sa_feature_static_data)\n",
    "    sa_target_bacth = create_batch(sa_target_surface_data, sa_target_atmos_data, sa_target_static_data)\n",
    "    \n",
    "    \n",
    "    target_tensor = sa_target_bacth.surf_vars[\"2t\"].squeeze()[1,:,:]\n",
    "    \n",
    "    print(\"Start\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(sa_feature_bacth)\n",
    "    output_tensor =  outputs.surf_vars[\"2t\"][0, 0]\n",
    "    print(\"Prediction done\")\n",
    "    loss = custom_rmse(target_tensor, output_tensor, sa_rmse_weights)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 54\u001b[0m\n\u001b[1;32m     50\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(sa_feature_bacth)\n\u001b[1;32m     51\u001b[0m loss , _ \u001b[38;5;241m=\u001b[39m rmse_fn(predictions\u001b[38;5;241m=\u001b[39m[pred], \n\u001b[1;32m     52\u001b[0m          target_batch\u001b[38;5;241m=\u001b[39msa_target_bacth, var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2t\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m          weigths\u001b[38;5;241m=\u001b[39msa_rmse_weights, area\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msa\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "\n",
    "sa_latitudes = target_sliced_era5_SA.latitude\n",
    "sa_longitudes = target_sliced_era5_SA.longitude\n",
    "sa_rmse_weights = rmse_weights(sa_latitudes, sa_longitudes)\n",
    "selected_times =  target_sliced_era5_SA.time\n",
    "sa_rmses_list=[]\n",
    "for i in range(0, len(target_sliced_era5_SA.time)-3):\n",
    "    # get current and previous time step data\n",
    "    world_feature_data =  (\n",
    "            target_sliced_era5_SA\n",
    "            .sel(time=slice(selected_times[i], selected_times[i+1]))\n",
    "        )\n",
    "    sa_feature_data =  (\n",
    "            sliced_era5_SA\n",
    "            .sel(time=slice(selected_times[i], selected_times[i+1]))\n",
    "        )\n",
    "\n",
    "    sa_target_data =  (\n",
    "            target_sliced_era5_SA\n",
    "            .sel(time=slice(selected_times[i+2], selected_times[i+3]))\n",
    "        )\n",
    "    \n",
    "    # get each type of data(surface, static atmosphere)\n",
    "\n",
    "    sa_feature_surface_data, sa_target_surface_data = get_surface_feature_target_data(sa_feature_data, sa_target_data)\n",
    "    sa_feature_atmos_data, sa_target_atmos_data = get_atmos_feature_target_data(sa_feature_data, sa_target_data)\n",
    "    sa_feature_static_data, sa_target_static_data = get_static_feature_target_data(sa_feature_data, sa_target_data)\n",
    "    \n",
    "    # create batch for each of them\n",
    "\n",
    "    sa_feature_bacth =  create_batch(sa_feature_surface_data, sa_feature_atmos_data, sa_feature_static_data)\n",
    "    sa_target_bacth = create_batch(sa_target_surface_data, sa_target_atmos_data, sa_target_static_data)\n",
    "    # get prediction\n",
    "    # sa_predictions = predict_fn(batch=sa_feature_bacth)\n",
    "    # # compute the rmse\n",
    "    \n",
    "    # sa_rmses, sa_pred_dates = rmse_fn(predictions=sa_predictions, \n",
    "    #         target_batch=sa_target_bacth, var_name=\"2t\",\n",
    "    #         weigths=sa_rmse_weights, area=\"sa\")\n",
    "    # # append result to the list\n",
    "    # world_rmses_list.append(world_rmses); pred_dates_list.append(world_pred_dates)\n",
    "    # sa_rmses_list.append(sa_rmses)\n",
    "    print(\"Start\")\n",
    "    \n",
    "\n",
    "\n",
    "    model = model.cuda()\n",
    "    model.train()\n",
    "    model.configure_activation_checkpointing()\n",
    "\n",
    "    pred = model.forward(sa_feature_bacth)\n",
    "    loss , _ = rmse_fn(predictions=[pred], \n",
    "             target_batch=sa_target_bacth, var_name=\"2t\",\n",
    "             weigths=sa_rmse_weights, area=\"sa\")\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_rmses, _ = rmse_fn(predictions=pred, \n",
    "             target_batch=sa_target_bacth, var_name=\"2t\",\n",
    "             weigths=sa_rmse_weights, area=\"sa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
