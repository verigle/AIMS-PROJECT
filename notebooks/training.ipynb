{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koomi_aims_ac_za/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from aurora import AuroraSmall, Batch, Metadata, rollout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cdsapi\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import gcsfs\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from aurora import Batch, Metadata\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    parameters, trainable = 0, 0\n",
    "    \n",
    "    for _, p in model.named_parameters():\n",
    "        parameters += p.numel()\n",
    "        trainable += p.numel() if p.requires_grad else 0\n",
    "    print(trainable)\n",
    "    print(f\"trainable parameters: {trainable:,}/{parameters:,} ({100 * trainable / parameters:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AuroraSmall(\n",
    "    use_lora=False,  # Model was not fine-tuned.\n",
    "    autocast=True,  # Use AMP.\n",
    ")\n",
    "model.load_state_dict(torch.load('../model/aurora-pretrained.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112797584\n",
      "trainable parameters: 112,797,584/112,797,584 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "trainable parameters: 0/112,797,584 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from lora import LinearWithLoRA\n",
    "# default hyperparameter choices\n",
    "lora_r = 8\n",
    "lora_alpha = 16\n",
    "# lora_dropout = 0.05\n",
    "# lora_query = True\n",
    "# lora_key = False\n",
    "# lora_value = True\n",
    "# lora_projection = False\n",
    "# lora_mlp = False\n",
    "# lora_head = False\n",
    "\n",
    "# layers = []\n",
    "\n",
    "assign_lora = partial(LinearWithLoRA, rank=lora_r, alpha=lora_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add lora to some parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone.time_mlp[0] = assign_lora(model.backbone.time_mlp[0])\n",
    "model.backbone.time_mlp[2] = assign_lora(model.backbone.time_mlp[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.backbone.encoder_layers:\n",
    "    for layer in block.blocks:\n",
    "        layer.norm1.ln_modulation[1] = assign_lora(layer.norm1.ln_modulation[1])\n",
    "        layer.attn.qkv = assign_lora(layer.attn.qkv)\n",
    "        layer.attn.proj = assign_lora(layer.attn.proj)\n",
    "        layer.norm2.ln_modulation[1] =  assign_lora(layer.norm2.ln_modulation[1])\n",
    "        layer.mlp.fc1 = assign_lora(layer.mlp.fc1)\n",
    "        layer.mlp.fc2 = assign_lora(layer.mlp.fc2)\n",
    "    if  block.downsample:\n",
    "        block.downsample.reduction = assign_lora(block.downsample.reduction)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.backbone.decoder_layers:\n",
    "    for layer in block.blocks:\n",
    "        layer.norm1.ln_modulation[1] = assign_lora(layer.norm1.ln_modulation[1])\n",
    "        layer.attn.qkv = assign_lora(layer.attn.qkv)\n",
    "        layer.attn.proj = assign_lora(layer.attn.proj)\n",
    "        layer.norm2.ln_modulation[1] =  assign_lora(layer.norm2.ln_modulation[1])\n",
    "        layer.mlp.fc1 = assign_lora(layer.mlp.fc1)\n",
    "        layer.mlp.fc2 = assign_lora(layer.mlp.fc2)\n",
    "    if  block.upsample:\n",
    "        block.upsample.lin1 = assign_lora(block.upsample.lin1)\n",
    "        block.upsample.lin2 = assign_lora(block.upsample.lin2)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"../model/checkpoints/checkpoint_epoch_20.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../model/initial_model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978368\n",
      "trainable parameters: 1,978,368/114,775,952 (1.72%)\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get south africa Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "\n",
    "store = fs.get_mapper('gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr')\n",
    "full_era5 = xr.open_zarr(store=store, consolidated=True, chunks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time, end_time = '2023-01-10', '2023-01-31'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lat_max = -22.00 \n",
    "lat_min = -37.75  \n",
    "\n",
    "lon_min = 15.25   \n",
    "lon_max = 35.00   \n",
    "sliced_era5_SA = (\n",
    "    full_era5\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import training\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import AuroraLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = AuroraLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 173.8280\n",
      "Epoch [2/20], Loss: 155.3041\n",
      "Epoch [3/20], Loss: 114.1772\n",
      "Epoch [4/20], Loss: 84.3582\n",
      "Epoch [5/20], Loss: 61.8708\n",
      "Epoch [6/20], Loss: 48.3436\n",
      "Epoch [7/20], Loss: 50.3122\n",
      "Epoch [8/20], Loss: 49.6999\n",
      "Epoch [9/20], Loss: 44.8104\n",
      "Checkpoint saved: ../model/checkpoints/checkpoint_epoch_10.pth\n",
      "Epoch [10/20], Loss: 41.3047\n",
      "Epoch [11/20], Loss: 39.8103\n",
      "Epoch [12/20], Loss: 38.3962\n",
      "Epoch [13/20], Loss: 36.8970\n",
      "Epoch [14/20], Loss: 35.9715\n",
      "Epoch [15/20], Loss: 35.5212\n",
      "Epoch [16/20], Loss: 34.8858\n",
      "Epoch [17/20], Loss: 34.0254\n",
      "Epoch [18/20], Loss: 32.9698\n",
      "Epoch [19/20], Loss: 31.9503\n",
      "Checkpoint saved: ../model/checkpoints/checkpoint_epoch_20.pth\n",
      "Epoch [20/20], Loss: 31.2207\n"
     ]
    }
   ],
   "source": [
    "model,  rmses = training(model=model, criterion=criterion,\n",
    "             num_epochs=20, optimizer=optimizer,\n",
    "             dataset= sliced_era5_SA,\n",
    "             dataset_name=\"ERA5\", \n",
    "             accumulation_steps=8,\n",
    "             checkpoint_dir = '../model/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../model/best_models/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path  = \"../report/training\"\n",
    "_, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "\n",
    "ax.plot(np.arange(1,len(rmses)+1), rmses)\n",
    "ax.set_ylabel(\"Mean Absolute Error (MAP)\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "plt.savefig(f\"{save_path}/map-learning-curve.pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(f\"{save_path}/map-learning-curve.png\", bbox_inches=\"tight\")\n",
    "plt.savefig(f\"{save_path}/map-learning-curve.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
