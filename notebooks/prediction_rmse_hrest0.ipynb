{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koomi_aims_ac_za/koomi/projects/AIMS-PROJECT/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from aurora import AuroraSmall, Batch, Metadata, rollout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cdsapi\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import gcsfs\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from aurora import Batch, Metadata\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AuroraSmall()\n",
    "\n",
    "model.load_state_dict(torch.load('../model/aurora.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "\n",
    "store = fs.get_mapper('gs://weatherbench2/datasets/hres_t0/2016-2022-6h-1440x721.zarr')\n",
    "full_hrest0 = xr.open_zarr(store=store, consolidated=True, chunks=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset data from 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2022-06-01'\n",
    "end_time = '2022-12-31'\n",
    "\n",
    "sliced_hrest0_world = (\n",
    "    full_hrest0\n",
    "    .sel(time=slice(start_time, end_time))\n",
    "    .isel(time=slice(None, -2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sliced_hrest0_world = (\n",
    "    full_hrest0\n",
    "    .sel(time=slice(start_time, end_time))  # Select the time range\n",
    "    .isel(time=slice(2, None))  # Skip the first two time steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Era 5 data for static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "\n",
    "store = fs.get_mapper('gs://weatherbench2/datasets/era5/1959-2023_01_10-wb13-6h-1440x721_with_derived_variables.zarr')\n",
    "full_era5 = xr.open_zarr(store=store, consolidated=True, chunks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2022-06-01'\n",
    "end_time = '2022-12-31'\n",
    "data_inner_steps = 6  \n",
    "\n",
    "sliced_era5_world = (\n",
    "    full_era5\n",
    "    .sel(time=slice(start_time, end_time))\n",
    "    .isel(time=slice(None, -2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sliced_era5_world = (\n",
    "    full_era5\n",
    "    .sel(time=slice(start_time, end_time))  # Select the time range\n",
    "    .isel(time=slice(2, None))  # Skip the first two time steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of surface variable names\n",
    "surface_vars = ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure']\n",
    "\n",
    "# Select surface variables\n",
    "surf_vars_ds = sliced_hrest0_world[surface_vars]\n",
    "target_surf_vars_ds = target_sliced_hrest0_world[surface_vars]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atmospherique variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "atmostpheric_variables = [\"temperature\", \"u_component_of_wind\", \"v_component_of_wind\", \"specific_humidity\", \"geopotential\"]\n",
    "atmos_vars_ds = sliced_hrest0_world[atmostpheric_variables]\n",
    "target_atmos_vars_ds = target_sliced_hrest0_world[atmostpheric_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_variables = [\"land_sea_mask\", \"soil_type\", \"geopotential_at_surface\"]\n",
    "static_vars_ds = sliced_era5_world[static_variables]\n",
    "target_static_vars_ds = target_sliced_era5_world[static_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare(x: np.ndarray, i) -> torch.Tensor:\n",
    "    \"\"\"Prepare a variable.\n",
    "\n",
    "    This does the following things:\n",
    "    * Select time indices `i` and `i - 1`.\n",
    "    * Insert an empty batch dimension with `[None]`.\n",
    "    * Flip along the latitude axis to ensure that the latitudes are decreasing.\n",
    "    * Copy the data, because the data must be contiguous when converting to PyTorch.\n",
    "    * Convert to PyTorch.\n",
    "    \"\"\"\n",
    "    return torch.from_numpy(x[[i - 1, i]][None][..., ::-1, :].copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ERA5ZarrDataset(Dataset):\n",
    "    def __init__(self, surf_vars_ds, atmos_vars_ds, static_vars_ds, sequence_length):\n",
    "        self.surf_vars_ds = surf_vars_ds\n",
    "        self.atmos_vars_ds = atmos_vars_ds\n",
    "        self.static_vars_ds = static_vars_ds\n",
    "        self.sequence_length = sequence_length\n",
    "        self.time_indices = range(sequence_length, len(surf_vars_ds.time))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.time_indices[idx]\n",
    "\n",
    "        batch = Batch(\n",
    "    surf_vars={\n",
    "        \"2t\": _prepare(surf_vars_ds[\"2m_temperature\"].values, i),\n",
    "        \"10u\": _prepare(surf_vars_ds[\"10m_u_component_of_wind\"].values, i),\n",
    "        \"10v\": _prepare(surf_vars_ds[\"10m_v_component_of_wind\"].values, i),\n",
    "        \"msl\": _prepare(surf_vars_ds[\"mean_sea_level_pressure\"].values, i),\n",
    "    },\n",
    "    static_vars = {\n",
    "            \"z\": torch.from_numpy(self.static_vars_ds[\"geopotential_at_surface\"].values),\n",
    "            \"slt\": torch.from_numpy(self.static_vars_ds[\"soil_type\"].values),\n",
    "            \"lsm\": torch.from_numpy(self.static_vars_ds[\"land_sea_mask\"].values),\n",
    "        },\n",
    "    atmos_vars={\n",
    "        \"t\": _prepare(atmos_vars_ds[\"temperature\"].values,i),\n",
    "        \"u\": _prepare(atmos_vars_ds[\"u_component_of_wind\"].values, i),\n",
    "        \"v\": _prepare(atmos_vars_ds[\"v_component_of_wind\"].values, i),\n",
    "        \"q\": _prepare(atmos_vars_ds[\"specific_humidity\"].values, i),\n",
    "        \"z\": _prepare(atmos_vars_ds[\"geopotential\"].values, i),\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        # Flip the latitudes! We need to copy because converting to PyTorch, because the\n",
    "        # data must be contiguous.\n",
    "        lat=torch.from_numpy(surf_vars_ds.latitude.values[::-1].copy()),\n",
    "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_vars_ds.time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.level.values),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_batches = ERA5ZarrDataset(surf_vars_ds, atmos_vars_ds, static_vars_ds,1)\n",
    "target_world_batches = ERA5ZarrDataset(target_surf_vars_ds, target_atmos_vars_ds, target_static_vars_ds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in world_batches:\n",
    "    data=batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### South Africa Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2022-06-01'\n",
    "end_time = '2022-12-31'\n",
    "\n",
    "lat_max = -22.00 \n",
    "lat_min = -37.75  \n",
    "\n",
    "lon_min = 15.25   \n",
    "lon_max = 35.00   \n",
    "\n",
    "sliced_hrest0_SA = (\n",
    "    full_hrest0\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )\n",
    "    .isel(time=slice(None, -2))\n",
    ")\n",
    "\n",
    "target_sliced_hrest0_SA = (\n",
    "    full_hrest0\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )  \n",
    "    .isel(time=slice(2, None))  # Skip the first two time steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = '2022-06-01'\n",
    "end_time = '2022-12-31'\n",
    "\n",
    "lat_max = -22.00 \n",
    "lat_min = -37.75  \n",
    "\n",
    "lon_min = 15.25   \n",
    "lon_max = 35.00   \n",
    "\n",
    "sliced_era5_SA = (\n",
    "    full_era5\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )\n",
    "    .isel(time=slice(None, -2))\n",
    ")\n",
    "\n",
    "target_sliced_era5_SA = (\n",
    "    full_era5\n",
    "    .sel(\n",
    "        time=slice(start_time, end_time),\n",
    "        latitude=slice(lat_max, lat_min),\n",
    "        longitude=slice(lon_min, lon_max)  \n",
    "    )  \n",
    "    .isel(time=slice(2, None))  # Skip the first two time steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_vars_ds_SA = sliced_hrest0_SA[surface_vars]\n",
    "\n",
    "target_surf_vars_ds_SA = target_sliced_hrest0_SA[surface_vars]\n",
    "\n",
    "atmos_vars_ds_SA = sliced_hrest0_SA[atmostpheric_variables]\n",
    "\n",
    "target_atmos_vars_ds_SA = target_sliced_hrest0_SA[atmostpheric_variables]\n",
    "\n",
    "static_vars_ds_SA = sliced_era5_SA[static_variables]\n",
    "\n",
    "target_static_vars_ds_SA = target_sliced_era5_SA[static_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_batches = ERA5ZarrDataset(surf_vars_ds_SA, atmos_vars_ds_SA, static_vars_ds_SA,1)\n",
    "target_SA_batches = ERA5ZarrDataset(target_surf_vars_ds_SA, target_atmos_vars_ds_SA, target_static_vars_ds_SA,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(model, batch):\n",
    "    model.eval()\n",
    "    model = model.to(\"cuda\")\n",
    "    with torch.inference_mode():\n",
    "        preds = [pred.to(\"cpu\") for pred in rollout(model, batch, steps=2)]\n",
    "    model = model.to(\"cpu\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom RMSE function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_weights(latitudes, longitudes, R=6371.0):\n",
    "    # convert to gradient\n",
    "    lat_rad = np.deg2rad(latitudes)\n",
    "    lon_rad = np.deg2rad(longitudes)\n",
    "    \n",
    "    dlat = np.abs(np.diff(lat_rad).mean())  # Average latitude difference\n",
    "    dlon = np.abs(np.diff(lon_rad).mean())  # Average longitude difference\n",
    "\n",
    "    # Calculate the area for each latitude band\n",
    "    areas = R**2 * dlon * np.abs(np.sin(lat_rad + dlat/2) - np.sin(lat_rad - dlat/2))\n",
    "\n",
    "    # Expand areas to match the shape of the grid\n",
    "    area_grid = np.outer(areas, np.ones(len(longitudes)))\n",
    "    area_grid = area_grid/area_grid.sum()\n",
    "    \n",
    "    \n",
    "    return area_grid\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### world rmse weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_rmse_weights = rmse_weights(sliced_era5_world.latitude, sliced_era5_world.longitude, R=6371.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### South Africa rmse weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_rmse_weights = rmse_weights(sliced_era5_SA.latitude, sliced_era5_SA.longitude, R=6371.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rmse(actual, prediction, weigths):\n",
    "    return (((actual-prediction)**2)*weigths).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSEs World dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_fn(model, feature_batch, target_batch, var_name, weigths=world_rmse_weights, var_type=\"surface\", atmos_level_idx=0):\n",
    "    predictions = predict_fn(model, batch=feature_batch)\n",
    "    two_steps_rmse = []\n",
    "    pred_dates = []\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "        if var_type==\"surface\":\n",
    "            prediction = pred.surf_vars[var_name][0, 0].numpy()\n",
    "            actual = target_batch.surf_vars[var_name].squeeze()[i,:,:][1:, :]\n",
    "            # actual = target_batch.surf_vars[var_name][0, 0].numpy()\n",
    "            \n",
    "            # rmse = root_mean_squared_error(actual.flatten(), prediction.flatten())\n",
    "            rmse_ = custom_rmse(actual, prediction, weigths[1:,:])\n",
    "            # print(rmse1)\n",
    "            two_steps_rmse.append(rmse_.item())\n",
    "            pred_dates.append(pred.metadata.time[0])\n",
    "        # Atmospherique variable\n",
    "        elif var_type==\"atmosphere\":\n",
    "            prediction = pred.atmos_vars[var_name].squeeze()[atmos_level_idx,:,:].numpy().squeeze()\n",
    "            # actual = target_batch.atmos_vars[var_name].squeeze()[i,:,:][1:, :]\n",
    "            actual = target_batch.atmos_vars[var_name].squeeze()[i,atmos_level_idx,:,:].numpy()[:-1,:]\n",
    "            # rmse = root_mean_squared_error(actual.flatten(), prediction.flatten())\n",
    "            rmse_ = custom_rmse(actual, prediction, weigths[1:,:])\n",
    "            two_steps_rmse.append(rmse_.item())\n",
    "            pred_dates.append(pred.metadata.time[0])\n",
    "    return two_steps_rmse, pred_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSEs South Africa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_fn_sa(model, actual_batch, target_batch, var_name, weigths=SA_rmse_weights, var_type=\"surface\",  atmos_level_idx=0):\n",
    "    predictions = predict_fn(model, batch=actual_batch)\n",
    "    two_steps_rmse = []\n",
    "    pred_dates = []\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "        if var_type==\"surface\":\n",
    "            # prediction = pred.surf_vars[var_name][0, 0].numpy()\n",
    "            # actual = actual_batch.surf_vars[var_name][0, 0].numpy()\n",
    "            # rmse = root_mean_squared_error(actual.flatten(), prediction.flatten())\n",
    "            prediction = pred.surf_vars[var_name][0, 0].numpy()\n",
    "            actual = target_batch.surf_vars[var_name].squeeze()[i,:,:]\n",
    "            # rmse1 = rmse(actual, prediction)\n",
    "            computed_rmse = custom_rmse(actual, prediction, weigths)\n",
    "            two_steps_rmse.append(computed_rmse.item())\n",
    "            pred_dates.append(pred.metadata.time[0])\n",
    "            # print(computed_rmse.item())\n",
    "        elif var_type==\"atmosphere\":\n",
    "            prediction = pred.atmos_vars[var_name].squeeze()[atmos_level_idx,:,:].numpy().squeeze()\n",
    "            actual = target_batch.atmos_vars[var_name].squeeze()[i,atmos_level_idx,:,:].numpy()\n",
    "            # rmse = root_mean_squared_error(actual.flatten(), prediction.flatten())\n",
    "            rmse_ = custom_rmse(actual, prediction, weigths)\n",
    "            two_steps_rmse.append(rmse_.item())\n",
    "            pred_dates.append(pred.metadata.time[0])\n",
    "    return two_steps_rmse, pred_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLot RMSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_rmses(variable, rmses_world, rmses_sa, \n",
    "               figsize=(12, 8), fontsize=18,\n",
    "               date_ranges=None, \n",
    "               title=\"Two Steps Forward Prediction: RMSEs\",\n",
    "               save_path=\"../report/rmses_world_SA\",\n",
    "               atmos_level=None):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=300)\n",
    "\n",
    "    # Extract dates\n",
    "    date_times_6_hours = [date1 for date1, date2 in date_ranges]\n",
    "    date_times_12_hours = [date2 for date1, date2 in date_ranges]\n",
    "    formatted_dates_6_hours = [dt.strftime('%Y-%m-%d (%H:%M)') for dt in date_times_6_hours]\n",
    "    formatted_dates_12_hours = [dt.strftime('%Y-%m-%d (%H:%M)') for dt in date_times_12_hours]\n",
    "\n",
    "    # Convert x-axis to indices\n",
    "    x_indices = np.arange(len(formatted_dates_6_hours))\n",
    "\n",
    "    # Select a subset of dates for x-axis labels\n",
    "    num_ticks = min(6, len(formatted_dates_6_hours))\n",
    "    tick_positions = np.linspace(0, len(formatted_dates_6_hours) - 1, num_ticks, dtype=int)\n",
    "\n",
    "    # Plot RMSEs with improved colors and styles\n",
    "    ax.plot(x_indices, np.array(rmses_world)[:, 0], label=\"Global RMSE (6h Forecast)\", color=\"blue\", linestyle=\"-\", linewidth=2)\n",
    "    ax.plot(x_indices, np.array(rmses_sa)[:, 0], label=\"South Africa RMSE (6h Forecast)\", color=\"orange\", linestyle=\"-\", linewidth=2)\n",
    "    ax.plot(x_indices, np.array(rmses_world)[:, 1], label=\"Global RMSE (12h Forecast)\", color=\"blue\", linestyle=\"--\", linewidth=2)\n",
    "    ax.plot(x_indices, np.array(rmses_sa)[:, 1], label=\"South Africa RMSE (12h Forecast)\", color=\"orange\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "    # Set selected x-ticks\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels([formatted_dates_12_hours[i] for i in tick_positions], rotation=30, ha='right')\n",
    "\n",
    "    # Improve legend appearance\n",
    "    ax.legend(title=\"Forecast Horizon\", title_fontsize=fontsize-2, fontsize=fontsize-4,\n",
    "              bbox_to_anchor=(1.05, 1), loc=\"upper left\", frameon=False)\n",
    "\n",
    "    # Improve axis labels and title\n",
    "    ax.set_xlabel(\"Forecast Date\", fontsize=fontsize-2)\n",
    "    ax.set_ylabel(\"Root Mean Squared Error (RMSE)\", fontsize=fontsize-2)\n",
    "    ax.set_title(title, fontsize=fontsize, pad=20)\n",
    "    if atmos_level:\n",
    "        # Save the plots\n",
    "        plt.savefig(f\"{save_path}/rmse-{variable}-{atmos_level}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.savefig(f\"{save_path}/rmse-{variable}-{atmos_level}.png\", bbox_inches=\"tight\")\n",
    "        plt.savefig(f\"{save_path}/rmse-{variable}-{atmos_level}.svg\", bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.savefig(f\"{save_path}/rmse-{variable}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.savefig(f\"{save_path}/rmse-{variable}.png\", bbox_inches=\"tight\", dpi=300)\n",
    "        plt.savefig(f\"{save_path}/rmse-{variable}.svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-meter temperature in K: 2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_world_2t = []\n",
    "dates_world_2t = []\n",
    "\n",
    "for batch, target_batch in zip(world_batches, target_world_batches):\n",
    "    rmse, date = rmse_fn(model, feature_batch=batch, target_batch=target_batch, var_name=\"2t\", var_type=\"surface\")\n",
    "    rmses_world_2t.append(rmse)\n",
    "    dates_world_2t.append(date)\n",
    "    del batch, target_batch, rmse, date\n",
    "    torch.cuda.empty_cache()  # Free GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_3476/3710106316.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  return (((actual-prediction)**2)*weigths).sum()\n"
     ]
    }
   ],
   "source": [
    "rmses_SA_2t = []\n",
    "dates_SA_2t = []\n",
    "for batch, target_batch in zip(SA_batches, target_SA_batches):\n",
    "    rmse_, date = rmse_fn_sa(model, actual_batch=batch, target_batch=target_batch, var_name=\"2t\", var_type=\"surface\")\n",
    "    rmses_SA_2t.append(rmse_)\n",
    "    dates_SA_2t.append(date)\n",
    "    del batch, target_batch, rmse_, date\n",
    "    torch.cuda.empty_cache()  # Free GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rmses(\"2t\",rmses_world_2t, rmses_SA_2t, \n",
    "            figsize=(15, 8), fontsize=18,\n",
    "            date_ranges=dates_world_2t, title=\"Two-meter temperature two steps forward prediction: RMSES\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
